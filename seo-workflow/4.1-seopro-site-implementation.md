# SEOPRO Site Implementation Guide

This guide walks you through implementing the SEOPRO Keywords API and Batch Processing API with minimal code additions. Follow these steps to get up and running quickly.

---

## 2. Keywords API Implementation

### 2.1 GET /api/seo/keywords/all

Create the file at `app/api/seo/keywords/all/route.ts`:

```ts
import { NextResponse } from "next/server";
import { db } from "@/db";
import { sql } from "drizzle-orm";

// Whitelist of allowed tables for security
const ALLOWED_TABLES = ['public.service_page'];

export async function GET(req: Request) {
  try {
    const { searchParams } = new URL(req.url);
    const table = searchParams.get('table');

    // Validate table parameter
    if (!table) {
      return NextResponse.json(
        { error: "Missing required 'table' parameter" },
        { status: 400 }
      );
    }

    if (!ALLOWED_TABLES.includes(table)) {
      return NextResponse.json(
        { error: "Invalid table parameter" },
        { status: 400 }
      );
    }

    // Get all existing keywords from the database using raw SQL for dynamic table
    const [schema, tableName] = table.split('.');
    const result = await db.execute<{ keyword: string, slug: string | null }>(
      sql`SELECT keyword, slug FROM ${sql.identifier(schema)}.${sql.identifier(tableName)}`
    );

    const keywords = result.map(row => row.keyword);

    return NextResponse.json({
      keywords,
      total: keywords.length,
      updatedAt: new Date().toISOString()
    });
  } catch (error) {
    console.error("Error fetching keywords:", error);
    return NextResponse.json(
      { error: "Internal server error" },
      { status: 500 }
    );
  }
   }
   ```

### 2.2 POST /api/seo/keywords/add

Create the file at `app/api/seo/keywords/add/route.ts`:

```ts
import { NextResponse } from "next/server";
import { db } from "@/db";
import { sql } from "drizzle-orm";

// CORS headers configuration
const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS",
  "Access-Control-Allow-Headers": "Content-Type, Authorization",
};

// Whitelist of allowed tables for security
const ALLOWED_TABLES = ['public.service_page'];

// Validation constants
const MAX_KEYWORD_LENGTH = 100;
const MAX_BATCH_SIZE = 50;

// OPTIONS handler for CORS preflight requests
export async function OPTIONS() {
  return NextResponse.json({}, { headers: corsHeaders });
}

export async function POST(req: Request) {
  try {
    const { searchParams } = new URL(req.url);
    const table = searchParams.get('table');

    // Validate table parameter
    if (!table) {
      return NextResponse.json(
        { error: "Missing required 'table' parameter" },
        { status: 400, headers: corsHeaders }
      );
    }

    if (!ALLOWED_TABLES.includes(table)) {
      return NextResponse.json(
        { error: "Invalid table parameter" },
        { status: 400, headers: corsHeaders }
      );
    }

    const { keywords } = await req.json();

    // Input validation
    if (!Array.isArray(keywords)) {
      return NextResponse.json(
        { error: "Invalid input: keywords must be an array" },
        { status: 400, headers: corsHeaders }
      );
    }

    if (keywords.length === 0) {
      return NextResponse.json(
        { error: "Keywords array cannot be empty" },
        { status: 400, headers: corsHeaders }
      );
    }

    if (keywords.length > MAX_BATCH_SIZE) {
      return NextResponse.json(
        { error: `Cannot add more than ${MAX_BATCH_SIZE} keywords at once` },
        { status: 400, headers: corsHeaders }
      );
    }

    // Validate individual keywords
    const invalidKeywords = keywords.filter(
      k => typeof k !== 'string' || k.length === 0 || k.length > MAX_KEYWORD_LENGTH
    );

    if (invalidKeywords.length > 0) {
      return NextResponse.json(
        { 
          error: "Invalid keywords found",
          details: `Keywords must be non-empty strings with maximum length of ${MAX_KEYWORD_LENGTH} characters`
        },
        { status: 400, headers: corsHeaders }
      );
    }

    try {
      // Parse schema and table
      const [schema = 'public', tableName] = table.split('.');
      if (!tableName) {
        return NextResponse.json(
          { error: "Invalid table format. Expected format: schema.table_name" },
          { status: 400, headers: corsHeaders }
        );
      }

      console.log('Attempting to insert keywords:', {
        schema,
        tableName,
        keywordsCount: keywords.length,
        sampleKeywords: keywords.slice(0, 3)
      });

      // Insert one keyword at a time to avoid SQL injection and syntax issues
      const results = [];
      for (const keyword of keywords) {
        const result = await db.execute<{ id: number, keyword: string }>(
          sql`
            INSERT INTO ${sql.identifier(schema)}.${sql.identifier(tableName)} 
            (keyword, created_at, last_edited_ts)
            VALUES (${keyword}, NOW(), NOW())
            RETURNING id, keyword
          `
        );
        if (result.length > 0) {
          results.push(result[0]);
        }
      }

      console.log('Successfully inserted keywords:', {
        insertedCount: results.length,
        sampleResults: results.slice(0, 3)
      });

      return NextResponse.json({
        success: true,
        added: results.length,
        keywords: results,
        total: results.length
      }, { headers: corsHeaders });
    } catch (dbError) {
      console.error('Database error:', {
        error: dbError,
        message: dbError instanceof Error ? dbError.message : 'Unknown database error',
        stack: dbError instanceof Error ? dbError.stack : undefined
      });
      
      return NextResponse.json(
        { error: "Database error occurred", details: dbError instanceof Error ? dbError.message : 'Unknown error' },
        { status: 500, headers: corsHeaders }
      );
    }
  } catch (error) {
    console.error("Error processing request:", {
      error,
      message: error instanceof Error ? error.message : 'Unknown error',
      stack: error instanceof Error ? error.stack : undefined
    });
    
    return NextResponse.json(
      { error: "Internal server error", details: error instanceof Error ? error.message : 'Unknown error' },
      { status: 500, headers: corsHeaders }
    );
  }
}

---

## 3. Batch Processing API Implementation

### 3.1 GET /api/seo/batch/tasks

Create a route file at `app/api/seo/batch/tasks/route.ts`:

```ts
import { db } from '@/db';
import { servicePage } from '@/db/schema';
import { asc, eq, sql } from 'drizzle-orm';
import { NextResponse } from 'next/server';

const VALID_STATUSES = ['empty', 'scheduled', 'running', 'success', 'failed'] as const;
type Status = typeof VALID_STATUSES[number];

// list keywords as tasks for SEO task management dashboard
export async function GET(request: Request) {
  try {
    const { searchParams } = new URL(request.url);
    const table = searchParams.get('table');
    const status = searchParams.get('status') as Status | null;
    const start = parseInt(searchParams.get('start') || '0');
    const size = parseInt(searchParams.get('size') || '20');

    // Validate pagination parameters
    if (isNaN(start) || start < 0) {
      return NextResponse.json(
        { error: 'Invalid start parameter. Must be a non-negative integer.' },
        { status: 400 }
      );
    }

    if (isNaN(size) || size <= 0) {
      return NextResponse.json(
        { error: 'Invalid size parameter. Must be a positive integer.' },
        { status: 400 }
      );
    }

    // Require valid table parameter
    if (!table || !['service_page'].includes(table)) {
      return NextResponse.json(
        { 
          error: 'Please specify a valid table parameter.',
          message: 'Supported values are: service_page'
        },
        { status: 400 }
      );
    }

    // Validate status if provided
    if (status && !VALID_STATUSES.includes(status)) {
      return NextResponse.json(
        {
          error: 'Invalid status parameter.',
          message: `Supported values are: ${VALID_STATUSES.join(', ')}`
        },
        { status: 400 }
      );
    }

    if (table === 'service_page') {
      // Get total count
      const [{ count }] = await db
        .select({
          count: sql<number>`count(*)`,
        })
        .from(servicePage)
        .where(status ? eq(servicePage.status, status) : undefined);

      // Get paginated results
      const result = await db
        .select({
          id: servicePage.id,
          keyword: servicePage.keyword,
          slug: servicePage.slug,
          status: servicePage.status,
          created_at: servicePage.created_at,
          last_edited_ts: servicePage.last_edited_ts,
        })
        .from(servicePage)
        .where(status ? eq(servicePage.status, status) : undefined)
        .orderBy(asc(servicePage.id))
        .limit(size)
        .offset(start);

      return NextResponse.json({
        items: result,
        total: Number(count),
        start,
        size,
        status
      });
    }

    // This should never be reached due to the validation above
    return NextResponse.json(
      { error: 'Invalid table parameter' },
      { status: 400 }
    );
  } catch (error) {
    console.error('Error fetching keywords:', error);
    return NextResponse.json(
      { error: 'Failed to fetch keywords' },
      { status: 500 }
    );
  }
   }
   ```

### 3.2 POST /api/seo/batch/tasks/schedule

Create a route file at `app/api/seo/batch/tasks/schedule/route.ts`:

```ts
import { db } from '@/db';
import { servicePage } from '@/db/schema';
import { and, eq, inArray, notInArray } from 'drizzle-orm';
import { NextResponse } from 'next/server';

const tableMap = {
  'service_page': servicePage,
} as const;

type TableName = keyof typeof tableMap;

export async function POST(request: Request) {
  try {
    const { table, taskIds, status } = await request.json();

    // Validate table parameter
    if (!table || !(table in tableMap)) {
      return NextResponse.json(
        { error: 'Invalid table parameter. Must be "service_page"' },
        { status: 400 }
      );
    }

    const selectedTable = tableMap[table as TableName];
    let result;

    // If status is empty, update all empty tasks to scheduled
    if (status && status === 'empty') {
      result = await db
        .update(selectedTable)
        .set({ 
          status: 'scheduled',
        })
        .where(eq(selectedTable.status, 'empty'))
        .returning({ id: selectedTable.id });
    }
    // If taskIds is provided and is an array, update specific tasks
    else if (taskIds && Array.isArray(taskIds) && taskIds.length > 0) {
      result = await db
        .update(selectedTable)
        .set({ 
          status: 'scheduled',
        })
        .where(and(inArray(selectedTable.id, taskIds), notInArray(selectedTable.status, ['scheduled', 'running'])))
        .returning({ id: selectedTable.id });
    }
    // Fallback to updating all empty status items
    else {
      result = await db
        .update(selectedTable)
        .set({ 
          status: 'scheduled',
        })
        .where(eq(selectedTable.status, 'empty'))
        .returning({ id: selectedTable.id });
    }

    return NextResponse.json({
      message: `Successfully scheduled ${result.length} items from ${table}`,
      updated_count: result.length,
      updated_ids: result.map(item => item.id)
    });

  } catch (error) {
    console.error('Error in scheduling tasks:', error);
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    );
  }
   }
   ```

---

## 4. Testing and Verification

Use `curl` or Postman to verify endpoints:

```bash
# Fetch existing keywords
curl "https://your-domain.com/api/seo/keywords/all?table=public.service_page"

# Add new keywords
curl -X POST "https://your-domain.com/api/seo/keywords/add?table=public.service_page" \
     -H "Content-Type: application/json" \
     -d '{"keywords":["test1","test2"]}'

# List batch tasks
curl "https://your-domain.com/api/seo/batch/tasks?start=0&size=100&table=public.service_page&status=empty"

# Schedule all empty
curl -X POST "https://your-domain.com/api/seo/batch/tasks/schedule" \
     -H "Content-Type: application/json" \
     -d '{"table":"public.service_page","status":"empty"}'
```

---

## 5. Automated Page Generation

To automatically process tasks that have been scheduled, implement the following components:

### 5.1 Cron Job Configuration (vercel.json)

Create/update `vercel.json` at the project root:

```json
{
  "functions": {
    "app/api/**/*": {
      "maxDuration": 300
    }
  },
  "crons": [{
      "path": "/api/seo/batch/ranger",
      "schedule": "* * * * *"
    }]
} 
```

This sets up a cron job that runs every minute to check for and process scheduled tasks.

### 5.2 Ranger Endpoint Implementation

Create a route file at `app/api/seo/batch/ranger/route.ts`: (using `service_page` only as an example)

```ts
import { NextResponse } from 'next/server';
import { db } from '@/db';
import { servicePage } from '@/db/schema';
import { eq, asc, inArray } from 'drizzle-orm';
import { runWorkflow } from '@/utils/seo-workflow/run-workflow';

export const dynamic = 'force-dynamic';
export const runtime = 'nodejs';
export const maxDuration = 300;

export async function GET() {
  try {
    // Get 1 scheduled tasks from service_page
    const serviceTasks = await db
      .select({
        id: servicePage.id,
      })
      .from(servicePage)
      .where(eq(servicePage.status, 'scheduled'))
      .orderBy(asc(servicePage.id))
      .limit(1);

    // Run workflows in background
    const serviceIds = serviceTasks.map(t => t.id);

    if (serviceIds.length === 0) {
      return NextResponse.json({
        message: 'No scheduled tasks found',
        success: true,
        scheduledIds: {
          service_page: [],
        },
      });
    }

    // Update statuses and run workflows concurrently
    const workflowPromises = [];

    if (serviceIds.length > 0) {
      // Update service_page status to running
      await db
        .update(servicePage)
        .set({ status: 'running' })
        .where(inArray(servicePage.id, serviceIds));

      workflowPromises.push(
        runWorkflow({
          workflowType: 'service_page',
          idInput: serviceIds.join(','),
        }).catch(error => {
          console.error('Background service_page workflow execution error:', error);
        })
      );
    }

    // Run all workflows concurrently
    await Promise.all(workflowPromises);

    console.log('serviceIds found: ', serviceIds);

    return NextResponse.json({
      message: 'Tasks scheduled for processing',
      success: true,
      scheduledIds: {
        service_page: serviceIds,
      },
    });
  } catch (error) {
    console.error('Ranger execution error:', error);
    return NextResponse.json(
      {
        error: error instanceof Error ? error.message : 'Internal server error',
        success: false,
      },
      { status: 500 }
    );
  }
}
```

### 5.3 Processing Flow

1. When tasks are set to "scheduled" via the `/api/seo/batch/tasks/schedule` endpoint
2. The cron job hits `/api/seo/batch/ranger` every minute
3. The ranger endpoint:
   - Finds the next scheduled task
   - Updates its status to "running"
   - Calls the `runWorkflow` function with the task ID
4. The workflow system then:
   - Executes the configured steps (e.g., content generation)
   - Updates the row with results
   - Sets final status to "success" or "failed"

This automated pipeline ensures that tasks are processed continuously without manual intervention.

---

## 6. Parallel Workflow Steps for Translation

To speed up multilingual content generation, translation steps can be wrapped in a single parallel workflow step. In your `service-page-seo-workflow.ts` configuration, you'll find the `parallelTranslations` definition:
```ts
145:152:utils/seo-workflow/configurations/service-page-seo-workflow.ts
const parallelTranslations: ParallelledExecutionStep = {
    type: 'parallel',
    name: 'Translations',
    steps: [
        translateEnToLang('ja'),
        translateEnToLang('zh-Hant'),
        translateEnToLang('ko'),
        translateEnToLang('es'),
        translateEnToLang('fr'),
        translateEnToLang('pt'),
        translateEnToLang('de'),
        translateEnToLang('it'),
        translateEnToLang('he'),
        translateEnToLang('ar'),
    ]
}
```

At runtime, the `executeWorkflow` function recognizes this step and launches all translations concurrently:
```ts
258:264:utils/seo-workflow/common-function.ts
if (isParallelledExecutionStep(step)) {
    console.log(`Step [${stepIdentifier}] >>>>>>>> Starting parallel execution of ${step.steps.length} steps...`);
    await Promise.all(step.steps.map(executeStep));
    console.log(`Step [${stepIdentifier}] <<<<<<<< Parallel execution completed`);
    return;
}
```

By grouping translation requests in this way, the system sends simultaneous API calls for each target language, reducing total translation time roughly in proportion to the number of languages (subject to rate limits). Ensure your deployment can handle the concurrency and adjust batched sizes if necessary.

### 6.1 Defining ParallelledExecutionStep in your Workflow Utilities

To enable parallel workflow steps in your shared utils (e.g., `dev-playbook/common-component/workflow-utils.ts`), add the following type definitions:
```ts
// ... existing imports and types ...

export interface ParallelledExecutionStep extends BaseWorkflowStep {
  type: 'parallel';
  steps: Array<
    SlugWorkflowStep |
    LlmWorkflowStep |
    TimestampWorkflowStep |
    GoogleSearchWorkflowStep |
    ConcatenateFieldsWorkflowStep
  >;
}

export type WorkflowStep =
  | SlugWorkflowStep
  | LlmWorkflowStep
  | TimestampWorkflowStep
  | GoogleSearchWorkflowStep
  | ConcatenateFieldsWorkflowStep
  | ParallelledExecutionStep;
```

This ensures that your shared workflow definitions can include parallel steps, and matches the runtime executor in `executeWorkflow` that handles the `parallel` type via `Promise.all`.

---

**Congratulations!** You have now implemented the complete SEOPRO system with keyword management, batch task scheduling, and automated content generation. Adjust database schemas and workflow steps to fit your specific needs.
1. 